{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport string\nfrom tqdm.notebook import tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom transformers import (set_seed,\n                          TrainingArguments,\n                          Trainer,\n                          GPT2Config,\n                          GPT2Tokenizer,\n                          AdamW,\n                          get_linear_schedule_with_warmup,\n                          GPT2ForSequenceClassification)\nimport gym","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:00:44.534200Z","iopub.execute_input":"2024-09-16T15:00:44.535055Z","iopub.status.idle":"2024-09-16T15:01:03.613176Z","shell.execute_reply.started":"2024-09-16T15:00:44.535016Z","shell.execute_reply":"2024-09-16T15:01:03.612138Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Hyper paramater","metadata":{}},{"cell_type":"code","source":"max_len = 64 # Max lenght of the text for input\nbatch_size = 32\nepochs = 6\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_labels = 4","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:03.615165Z","iopub.execute_input":"2024-09-16T15:01:03.616279Z","iopub.status.idle":"2024-09-16T15:01:03.653892Z","shell.execute_reply.started":"2024-09-16T15:01:03.616232Z","shell.execute_reply":"2024-09-16T15:01:03.652738Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# loading data","metadata":{}},{"cell_type":"code","source":"df = pd.read_json(\"hf://datasets/NathanGavenski/LunarLander-v2/teacher.jsonl\", lines=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:03.655297Z","iopub.execute_input":"2024-09-16T15:01:03.655711Z","iopub.status.idle":"2024-09-16T15:01:07.931335Z","shell.execute_reply.started":"2024-09-16T15:01:03.655649Z","shell.execute_reply":"2024-09-16T15:01:07.930507Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading model and tokenizer","metadata":{}},{"cell_type":"code","source":"print('Loading gpt-2 model')\nmodel_config = GPT2Config.from_pretrained(pretrained_model_name_or_path='gpt2', num_labels=4)\n\nprint('Loading tokenizer...')\ntokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path='gpt2')\ntokenizer.padding_side = \"left\"\ntokenizer.pad_token = tokenizer.eos_token\n\nprint('Loading model...')\nmodel = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path='gpt2', config=model_config)\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.config.pad_token_id = model.config.eos_token_id\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:07.933852Z","iopub.execute_input":"2024-09-16T15:01:07.934184Z","iopub.status.idle":"2024-09-16T15:01:12.274538Z","shell.execute_reply.started":"2024-09-16T15:01:07.934149Z","shell.execute_reply":"2024-09-16T15:01:12.273514Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Loading gpt-2 model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd939e526dd46e7a436c410c3bccbf4"}},"metadata":{}},{"name":"stdout","text":"Loading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68bb9244a6ba48a3b454e779328f3353"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1812f0253d74cd39bb96bf90c819618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ec70fc29735437586f0d91d90f058b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76f804c096e407cb2d236c85e1e0ed3"}},"metadata":{}},{"name":"stdout","text":"Loading model...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62bc6dd33fba487dbbe6c99603655656"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=4, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:12.275649Z","iopub.execute_input":"2024-09-16T15:01:12.275991Z","iopub.status.idle":"2024-09-16T15:01:12.293060Z","shell.execute_reply.started":"2024-09-16T15:01:12.275957Z","shell.execute_reply":"2024-09-16T15:01:12.292251Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                 obs  actions   rewards  \\\n0  [0.001747226691804, 1.399963617324829, 0.17696...        2  1.145592   \n1  [0.003545951796695, 1.38917601108551, 0.181636...        2  2.836008   \n2  [0.005403709597885001, 1.378986597061157, 0.18...        2  3.144166   \n3  [0.007226371672004001, 1.36941385269165, 0.183...        2  2.811070   \n4  [0.009204101748764001, 1.360573768615722, 0.19...        2  0.116871   \n\n   episode_starts  \n0               1  \n1               0  \n2               0  \n3               0  \n4               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs</th>\n      <th>actions</th>\n      <th>rewards</th>\n      <th>episode_starts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.001747226691804, 1.399963617324829, 0.17696...</td>\n      <td>2</td>\n      <td>1.145592</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.003545951796695, 1.38917601108551, 0.181636...</td>\n      <td>2</td>\n      <td>2.836008</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.005403709597885001, 1.378986597061157, 0.18...</td>\n      <td>2</td>\n      <td>3.144166</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.007226371672004001, 1.36941385269165, 0.183...</td>\n      <td>2</td>\n      <td>2.811070</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0.009204101748764001, 1.360573768615722, 0.19...</td>\n      <td>2</td>\n      <td>0.116871</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['obs'] = df['obs'].apply(lambda obs: ' '.join([f\"{x:.6f}\" for x in obs]))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:12.294198Z","iopub.execute_input":"2024-09-16T15:01:12.294553Z","iopub.status.idle":"2024-09-16T15:01:13.830996Z","shell.execute_reply.started":"2024-09-16T15:01:12.294508Z","shell.execute_reply":"2024-09-16T15:01:13.829955Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Dataset and Collator","metadata":{}},{"cell_type":"code","source":"class DatasetCreator(Dataset):\n    def __init__(self, processed_data, train):\n        self.data = processed_data\n        self.train = train\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        line = self.data.iloc[index]\n        if self.train:\n            return {'text': line['obs'], 'label': line['actions']}\n        else:\n            return {'text': line['obs'], 'label': 0}\n\n# Class to tokenize and process the text for input to the dataloader\nclass GPT2_collator(object):\n    def __init__(self, tokenizer, max_seq_len=512):\n        self.tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n        return\n\n    def __call__(self, sequences):\n        texts = [sequence['text'] for sequence in sequences]\n        labels = [int(sequence['label']) for sequence in sequences]\n        inputs = self.tokenizer(text=texts,\n                                return_tensors='pt',\n                                padding=True,\n                                truncation=True,\n                                max_length=self.max_seq_len)\n        inputs.update({'labels': torch.tensor(labels)})\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:13.832264Z","iopub.execute_input":"2024-09-16T15:01:13.832662Z","iopub.status.idle":"2024-09-16T15:01:13.845820Z","shell.execute_reply.started":"2024-09-16T15:01:13.832619Z","shell.execute_reply":"2024-09-16T15:01:13.844660Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Training function","metadata":{}},{"cell_type":"code","source":"# Function for training\ndef train(dataloader, optimizer, scheduler, device):\n    global model\n    model.train()\n    predictions_labels = []\n    true_labels = []\n    total_loss = 0\n\n    for batch in tqdm(dataloader, total=len(dataloader)):\n        true_labels += batch['labels'].numpy().flatten().tolist()\n        batch = {k:v.type(torch.long).to(device) for k,v in batch.items()}\n        optimizer.zero_grad()\n        outputs = model(**batch)\n        loss, logits = outputs[:2]\n        total_loss += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n    avg_epoch_loss = total_loss / len(dataloader)\n    return predictions_labels, true_labels, avg_epoch_loss","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:13.847434Z","iopub.execute_input":"2024-09-16T15:01:13.847987Z","iopub.status.idle":"2024-09-16T15:01:13.943843Z","shell.execute_reply.started":"2024-09-16T15:01:13.847951Z","shell.execute_reply":"2024-09-16T15:01:13.942937Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Validation function","metadata":{}},{"cell_type":"code","source":"# Function for validation\ndef validate(dataloader, device):\n    global model\n    model.eval()\n    predictions_labels = []\n    true_labels = []\n    total_loss = 0\n\n    for batch in tqdm(dataloader, total=len(dataloader)):\n        true_labels += batch['labels'].numpy().flatten().tolist()\n        batch = {k:v.type(torch.long).to(device) for k,v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n            loss, logits = outputs[:2]\n            total_loss += loss.item()\n            predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n    avg_epoch_loss = total_loss / len(dataloader)\n    return predictions_labels, true_labels, avg_epoch_loss","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:13.945047Z","iopub.execute_input":"2024-09-16T15:01:13.945382Z","iopub.status.idle":"2024-09-16T15:01:13.954578Z","shell.execute_reply.started":"2024-09-16T15:01:13.945342Z","shell.execute_reply":"2024-09-16T15:01:13.953725Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Predict Func","metadata":{}},{"cell_type":"code","source":"def predict(dataloader, device):\n    global model\n    model.eval()\n    predictions_labels = []\n\n    for batch in tqdm(dataloader, total=len(dataloader)):\n        batch = {k:v.type(torch.long).to(device) for k,v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n            _, logits = outputs[:2]\n            predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n    return predictions_labels","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:13.958340Z","iopub.execute_input":"2024-09-16T15:01:13.958654Z","iopub.status.idle":"2024-09-16T15:01:13.970416Z","shell.execute_reply.started":"2024-09-16T15:01:13.958609Z","shell.execute_reply":"2024-09-16T15:01:13.969726Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_val = df[0:19000]\ndf_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:13.971465Z","iopub.execute_input":"2024-09-16T15:01:13.971852Z","iopub.status.idle":"2024-09-16T15:01:13.984334Z","shell.execute_reply.started":"2024-09-16T15:01:13.971809Z","shell.execute_reply":"2024-09-16T15:01:13.983323Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(19000, 4)"},"metadata":{}}]},{"cell_type":"code","source":"gpt2_collator = GPT2_collator(tokenizer=tokenizer, max_seq_len=max_len)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:13.985655Z","iopub.execute_input":"2024-09-16T15:01:13.986260Z","iopub.status.idle":"2024-09-16T15:01:13.992802Z","shell.execute_reply.started":"2024-09-16T15:01:13.986217Z","shell.execute_reply":"2024-09-16T15:01:13.991882Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Train Test split","metadata":{}},{"cell_type":"code","source":"train_data = DatasetCreator(df, train=True)\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=gpt2_collator)\n\n\nval_data = DatasetCreator(df_val, train=True)\nval_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=gpt2_collator)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:13.994093Z","iopub.execute_input":"2024-09-16T15:01:13.994480Z","iopub.status.idle":"2024-09-16T15:01:14.002300Z","shell.execute_reply.started":"2024-09-16T15:01:13.994437Z","shell.execute_reply":"2024-09-16T15:01:14.001406Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-8, weight_decay=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:14.003528Z","iopub.execute_input":"2024-09-16T15:01:14.004144Z","iopub.status.idle":"2024-09-16T15:01:14.430012Z","shell.execute_reply.started":"2024-09-16T15:01:14.004099Z","shell.execute_reply":"2024-09-16T15:01:14.429210Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for x in val_dataloader:\n    print(tokenizer.decode(x['input_ids'][0]))\n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:14.431118Z","iopub.execute_input":"2024-09-16T15:01:14.431422Z","iopub.status.idle":"2024-09-16T15:01:14.461696Z","shell.execute_reply.started":"2024-09-16T15:01:14.431390Z","shell.execute_reply":"2024-09-16T15:01:14.460838Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>0.049382 -0.001237 -0.000006 -0.000000 -0.000409 0.000002 1.000000 1.000000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"total_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\nloss = []\naccuracy = []\nval_loss_list = []\nval_accuracy_list = []\n\nfor epoch in tqdm(range(epochs)):\n    train_labels, true_labels, train_loss = train(train_dataloader, optimizer, scheduler, device)\n    train_acc = accuracy_score(true_labels, train_labels)\n    print('epoch: %.2f train accuracy %.2f' % (epoch, train_acc))\n    loss.append(train_loss)\n    accuracy.append(train_acc)\n\n    val_labels, val_true_labels, val_loss = validate(val_dataloader, device)\n    val_acc= accuracy_score(val_true_labels, val_labels)\n    print('epoch: %.2f validation accuracy %.2f' % (epoch, val_acc))\n    val_loss_list.append(val_loss)\n    val_accuracy_list.append(val_acc)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T15:01:14.462729Z","iopub.execute_input":"2024-09-16T15:01:14.463019Z","iopub.status.idle":"2024-09-16T18:20:15.713485Z","shell.execute_reply.started":"2024-09-16T15:01:14.462988Z","shell.execute_reply":"2024-09-16T18:20:15.712400Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a48d17e2e85640a99146c0109c318a56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e28db539f8544d5ca41e833e4803435f"}},"metadata":{}},{"name":"stdout","text":"epoch: 0.00 train accuracy 0.80\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b502d122fdd14e66b8e33499c013d154"}},"metadata":{}},{"name":"stdout","text":"epoch: 0.00 validation accuracy 0.86\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac833cff855424287524435fd8a18cc"}},"metadata":{}},{"name":"stdout","text":"epoch: 1.00 train accuracy 0.87\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ad808661fea40548debaf6cfd5ce3d4"}},"metadata":{}},{"name":"stdout","text":"epoch: 1.00 validation accuracy 0.90\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc490e28ed44b0f8eb048dd21bbf13c"}},"metadata":{}},{"name":"stdout","text":"epoch: 2.00 train accuracy 0.90\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a63bd1a85074320b7cf90d1d48f47b4"}},"metadata":{}},{"name":"stdout","text":"epoch: 2.00 validation accuracy 0.93\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8a43ad09ee04ca59858f3eb6f82497c"}},"metadata":{}},{"name":"stdout","text":"epoch: 3.00 train accuracy 0.92\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600bd1dee65247a68ba2016fc7ab2840"}},"metadata":{}},{"name":"stdout","text":"epoch: 3.00 validation accuracy 0.93\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fec0badc0bb486695b6c4506c24f1a9"}},"metadata":{}},{"name":"stdout","text":"epoch: 4.00 train accuracy 0.93\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dea67cab8224abcbaa4d421603897ff"}},"metadata":{}},{"name":"stdout","text":"epoch: 4.00 validation accuracy 0.96\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92932200b22b4fe681138a9eb3c8b742"}},"metadata":{}},{"name":"stdout","text":"epoch: 5.00 train accuracy 0.94\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdfb0aadf4d34741a3218a2c6dd251c1"}},"metadata":{}},{"name":"stdout","text":"epoch: 5.00 validation accuracy 0.97\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\n\ndef predict_and_get_true_labels(dataloader, device):\n    global model\n    model.eval()\n    predictions_labels = []\n    true_labels = []\n\n    for batch in tqdm(dataloader, total=len(dataloader)):\n        # Assuming the batch contains 'labels' for true labels\n        true_labels += batch['labels'].flatten().tolist()\n\n        batch = {k: v.type(torch.long).to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n            _, logits = outputs[:2]\n            predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n\n    return predictions_labels, true_labels\n\n# Assuming dataloader contains true labels under the key 'labels'\npredictions, true_labels = predict_and_get_true_labels(val_dataloader, device)\n\n# Create the confusion matrix\nconf_matrix = confusion_matrix(true_labels, predictions)\n\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:22:29.978272Z","iopub.execute_input":"2024-09-16T18:22:29.978717Z","iopub.status.idle":"2024-09-16T18:23:02.042601Z","shell.execute_reply.started":"2024-09-16T18:22:29.978651Z","shell.execute_reply":"2024-09-16T18:23:02.041615Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/594 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d2a5ff09af4c089187c98434a879e9"}},"metadata":{}},{"name":"stdout","text":"Confusion Matrix:\n[[5407   61   53   95]\n [  53 1827   28    2]\n [  31   24 9466   27]\n [  84    8   52 1782]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(true_labels, predictions))","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:23:08.274805Z","iopub.execute_input":"2024-09-16T18:23:08.275282Z","iopub.status.idle":"2024-09-16T18:23:08.322048Z","shell.execute_reply.started":"2024-09-16T18:23:08.275246Z","shell.execute_reply":"2024-09-16T18:23:08.321129Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.97      0.96      0.97      5616\n           1       0.95      0.96      0.95      1910\n           2       0.99      0.99      0.99      9548\n           3       0.93      0.93      0.93      1926\n\n    accuracy                           0.97     19000\n   macro avg       0.96      0.96      0.96     19000\nweighted avg       0.97      0.97      0.97     19000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:23:12.704534Z","iopub.execute_input":"2024-09-16T18:23:12.705386Z","iopub.status.idle":"2024-09-16T18:23:12.727975Z","shell.execute_reply.started":"2024-09-16T18:23:12.705346Z","shell.execute_reply":"2024-09-16T18:23:12.727150Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93816d5bbc5e4c6fa2ba8e41979224ec"}},"metadata":{}}]},{"cell_type":"code","source":"model.push_to_hub(\"ErnestBeckham/gptController\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:23:38.205530Z","iopub.execute_input":"2024-09-16T18:23:38.206389Z","iopub.status.idle":"2024-09-16T18:23:56.878431Z","shell.execute_reply.started":"2024-09-16T18:23:38.206348Z","shell.execute_reply":"2024-09-16T18:23:56.877348Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954b957710d04fef8de650a3e94175fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93034b80ae1346a593276d0002eff86c"}},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ErnestBeckham/gptController/commit/79bed1060b52548b111a6ef1bb8b05d8c5b7b095', commit_message='Upload GPT2ForSequenceClassification', commit_description='', oid='79bed1060b52548b111a6ef1bb8b05d8c5b7b095', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}